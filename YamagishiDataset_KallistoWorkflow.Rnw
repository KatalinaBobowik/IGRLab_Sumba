\documentclass[a4paper]{article}

\usepackage{listings}
\usepackage{inconsolata}

<<echo=FALSE>>=
  options(width=65)

listing <- function(x, options) {
    paste("\\begin{lstlisting}[basicstyle=\\ttfamily,breaklines=true]\n",
      x, "\\end{lstlisting}\n", sep = "")
  }
  knit_hooks$set(source=listing, output=listing)
@

\begin{document}
\SweaveOpts{concordance=TRUE}

<<tidy=TRUE,highlight=FALSE,message=F, warning=F>>=
library(Rsubread)
library(RColorBrewer)
library(edgeR)
library(Homo.sapiens)
library(limma)
library(tximport)
library(tximportData)
library(ensembldb)
library(EnsDb.Hsapiens.v75)
library(rhdf5)
library(readr)
@


<<tidy=TRUE,highlight=FALSE>>=
### Check quality of reads from SRA Run selector by mapping the total number of mapped and unmapped reads
# Mapped reads
readSummary=read.table("/home/users/ntu/kbobowik/Sumba/Human_BWA_AlignmentStats/humanAlignment_all_YamagishiReads_PysamSummaryStatistics.txt", as.is=T, header=F, sep=" ")
colnames(readSummary) <- c("SRA_Accession_Number", "Total", "Mapped", "Unmapped", "QC_Fail", "Mapping_quality_lessThan_30")
@

<<tidy=TRUE,highlight=FALSE>>=
### Check quality of reads from SRA Run selector by mapping the total number of mapped and unmapped reads
readSummary=read.table("/home/users/ntu/kbobowik/Sumba/Human_BWA_AlignmentStats/humanAlignment_all_YamagishiReads_PysamSummaryStatistics.txt", as.is=T, header=F, sep=" ")
colnames(readSummary) <- c("SRA_Accession_Number", "Total", "Mapped", "Unmapped", "QC_Fail", "Mapping_quality_lessThan_30")

# Organise df by accession number
readSummary=readSummary[order(readSummary$SRA_Accession_Number),]
barplot(t(readSummary[,3:4])*1e-6, col=c("blue","red"), ylim=c(0, max(readSummary$Total)*1e-6+20), names.arg=readSummary$SRA_Accession_Number, las=3, cex.names=0.75, ylab="Total Mapped/Unmapped")
mtext("Reads", side=1, line=5)
legend("topright", legend=c("Mapped","Unmapped"), fill=c("blue", "red"))
@

<<tidy=TRUE,highlight=FALSE, message=F, warning=F>>=
### Read in count data using tximport
edb <- EnsDb.Hsapiens.v75
Tx.ensemble <- transcripts(edb, columns = c("tx_id", "gene_id", "gene_name"), return.type = "DataFrame")
tx2gene<- Tx.ensemble[,c(1,2)]
dir="/home/users/ntu/kbobowik/scratch/Kallisto/Human_PF_Combined"
samples=list.files(dir, pattern="DRR")
kallisto.files <- file.path(dir, samples, "noDecimal_abundance.tsv")
names(kallisto.files)<- samples
all(file.exists(kallisto.files))
tx.kallisto <- tximport(kallisto.files, type = "kallisto", tx2gene = tx2gene, reader = read_tsv)
# transcripts missing genes: 24659

y <- DGEList(tx.kallisto$counts)

# Gene annotation: A second data frame named genes in the DGEList-object is used to store gene-level information associated with rows of the counts matrix (retrieved using Homo.sapien package)
geneid <- rownames(y)
genes <- select(Homo.sapiens, keys=geneid, columns=c("SYMBOL", "TXCHROM"), keytype="ENSEMBL")

# Check for and remove duplicated gene IDs, then add genes dataframe to DGEList object
genes <- genes[!duplicated(genes$ENSEMBL),]
y$genes <- genes
@

<<tidy=TRUE,highlight=FALSE>>=
# Visualise library size and number of genes
cols <- brewer.pal(12,"Set3")
barplot(y$samples$lib.size*1e-6, ylab="Library size (millions)", cex.names=0.75, col=cols, las=3, ylim=c(0,max(y$samples$lib.size*1e-6)+10))
@

<<tidy=TRUE,highlight=FALSE>>=
barplot(apply(y$counts, 2, function(c)sum(c!=0)), ylab="n Genes", cex.names=0.75, col=cols, las=3)
@

<<tidy=TRUE,highlight=FALSE>>=
# Filter out samples with library size <10 million
y=y[,which(y$samples$lib.size >= 10000000)]

# Visualise library size after filtering
cols <- brewer.pal(12,"Set3")
barplot(y$samples$lib.size*1e-6, ylab="Library size (millions)", cex.names=0.75, col=cols, las=3, ylim=c(0,max(y$samples$lib.size*1e-6)+10))
@

<<tidy=TRUE,highlight=FALSE>>=
barplot(apply(y$counts, 2, function(c)sum(c!=0)), ylab="n Genes", cex.names=0.75, col=cols, las=3)
@

<<tidy=TRUE,highlight=FALSE>>=
### Assign group
# Make new table from Yamagishi et al 2014 supplementary table 11 (which has paients names, age, and sex) and SRA Run table (Study: DRP000987) 
sup11=read.delim("/home/users/ntu/kbobowik/Sumba/Yamagishi2014_Supplemental_Table_11.txt", as.is=T, strip.white=T)
sra=read.delim("/home/users/ntu/kbobowik/Sumba/SraRunTable.txt", as.is=T, strip.white=T)

# Create empty matrix and fill in with patient names, Age, Sex, and SRA Run ID
sample_summary=matrix("NA",nrow=nrow(sup11),ncol=5)
sample_summary[,1:3]=c(sup11$Patient_Name,sup11$Age, sup11$Sex)
colnames(sample_summary)=c("Patient_Name", "Age", "Sex", "SRA_ID", "sample_ID")

# Discrepancy in SRA table and Supplementary 11 table (i.e., one says "malaria7#09" and one says "malaria7#009"
sample_summary[103,1]="malaria7#009"

# Match patient names (taken from the supplementary 11 table) with the patient names in the SRA table, then grab the corresponding SRA run IDs (column 7)
sample_summary[,4]=sra[match(sample_summary[,1], sra[,4]),7]
sample_summary[,5]=paste("aligned_human_",sample_summary[,4],".sam", sep="")

gender <- sample_summary[match(colnames(y), sample_summary[,4]),3]
gender[is.na(gender)] <- "N"
group=as.factor(gender)
y$samples$group <- group
age <- sample_summary[match(colnames(y), sample_summary[,4]),2]
age[is.na(age)] <- "N"
age <- as.factor(age)
y$samples$age <- age

### Data pre-processing
# Raw counts are converted to CPM and log-CPM values
# Prior count for logCPM = 0.25
cpm <- cpm(y) 
lcpm <- cpm(y, log=TRUE)
full.lib.y <- y

# Remove genes that are lowly expressed- a gene is only retained if it is expressed at log-CPM > 1 in at least half of the libraries
keep.exprs <- rowSums(lcpm>1) >= (nrow(y$samples)*0.5)
y <- y[keep.exprs,, keep.lib.sizes=FALSE]

# Compare library sizes before and after removing lowly-expressed genes
nsamples <- ncol(y)
col <- colorRampPalette(brewer.pal(nsamples, "Paired")) (nsamples)
par(mfrow=c(1,2))
plot(density(lcpm[,1]), col=col[1], lwd=2, ylim=c(0,max(density(lcpm)$y)+.2), las=2, main="", xlab="")
title(main="A. Raw data", xlab="Log-cpm")
abline(v=0, lty=3)
for (i in 2:nsamples){
    den <- density(lcpm[,i])
    lines(den$x, den$y, col=col[i], lwd=2)
}

lcpm <- cpm(y, log=TRUE)
plot(density(lcpm[,1]), col=col[1], lwd=2, ylim=c(0,0.31), las=2, main="", xlab="")
title(main="B. Filtered data", xlab="Log-cpm")
abline(v=0, lty=3)
for (i in 2:nsamples){
    den <- density(lcpm[,i])
    lines(den$x, den$y, col=col[i], lwd=2)
}
@

Here, we normalise gene expression distributions to ensure that the expression distributions of each sample are similar across the entire experiment (i.e., no bias introduced during sample preparation/sequencing)

<<tidy=TRUE,highlight=FALSE>>=
y <- calcNormFactors(y, method = "TMM")

# Duplicate data, set normalisation back to 1, and plot difference between normalised and non-normalised data
y2 <- y
y2$samples$norm.factors <- 1
lcpm <- cpm(y2, log=TRUE)
boxplot(lcpm, las=2, col=col, main="")
title(main="A. Example: Unnormalised data",ylab="Log-cpm")
y2 <- calcNormFactors(y2)
lcpm <- cpm(y2, log=TRUE)
boxplot(lcpm, las=2, col=col, main="")
title(main="B. Example: Normalised data",ylab="Log-cpm")
@

<<tidy=TRUE,highlight=FALSE>>=
# MDS
lcpm <- cpm(y, log=TRUE)
col.group <- group
levels(col.group) <- brewer.pal(nlevels(col.group), "Set1")
col.group <- as.character(col.group)
col.age=cut(as.numeric(as.character(age)), c(0,15,30,70))
levels(col.age) <- brewer.pal(nlevels(col.age),"Set1")
col.age <- as.character(col.age)
plotMDS(lcpm, labels=group, col=col.group)
title(main="A. Sample Gender")
plotMDS(lcpm, labels=age, col=col.age)
title(main="A. Sample Age")
@

Make a design matrix. The whole purpose of the design matrix is to set up your parameters for estimating the relationships among your  variables (linear regression)

<<tidy=TRUE,highlight=FALSE>>=
design <- model.matrix(~0+gender)
colnames(design) <- levels(group)
contr.matrix <- makeContrasts(MvsF=M-F, MvsNA=M-N, FvsNA=F-N, levels=colnames(design))

# Voom: linear modelling is carried out on the log-CPM values which are assumed to be normally distributed and the mean-variance relationship is accommodated using precision weights calculated by the voom function. When operating on a DGEList-object, voom converts raw counts to log-CPM values by automatically extracting library sizes and normalisation factors from x itself.
v <- voom(y, design, plot=TRUE)
@

<<tidy=TRUE,highlight=FALSE>>=
# Empirical Bayes moderation is carried out by borrowing information across all genes to obtain more precise estimates of gene-wise variability. The modelâ€™s residual variances are plotted against average expression values
vfit <- lmFit(v, design)
vfit <- contrasts.fit(vfit, contrasts=contr.matrix)
efit <- eBayes(vfit)
plotSA(efit)
@

<<tidy=TRUE,highlight=FALSE>>=
# Summarise the number of significantly up- and down-regulated genes
topTable(efit)
dt <- decideTests(efit)
summary(dt)
@

<<tidy=TRUE,highlight=FALSE>>=
de.common <- which(dt[,1]!=0 & dt[,2]!=0)
head(tfit$genes$SYMBOL[de.common], n=20)
vennDiagram(dt[,1:2], circle.col=c("turquoise", "salmon"))
write.fit(efit, dt, file="results.txt")
@

<<tidy=TRUE,highlight=FALSE>>=
# Examine top DE genes
M.vs.F <- topTreat(efit, coef=1, n=Inf)
M.vs.NA <- topTreat(efit, coef=2, n=Inf)

plotMD(efit, column=1, status=dt[,1], main=colnames(efit)[1], xlim=c(-8,13))
@

\end{document}